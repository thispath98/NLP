{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thispath98/NLP/blob/main/Seq2Seq/Seq2Seq_with_Attention_Machine_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arhV3EqlUBl5"
      },
      "source": [
        "Reference\n",
        "- [bentrevett](https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb)\n",
        "- [나동빈](https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/Sequence_to_Sequence_with_Attention_Tutorial.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5cmQnSNeO1u"
      },
      "source": [
        "# Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WndlVD33WtbU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g01fci5KlJn",
        "outputId": "4a81e9bd-1f02-43f8-bb3c-cfc98d03438c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 981 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-py3-none-any.whl size=14907055 sha256=468f1c163ebcb763a43225a321dd5090fb3758f2d619d0323adc8ca28a92837e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ixm7_ixw/wheels/00/66/69/cb6c921610087d2cab339062345098e30a5ceb665360e7b32a\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "영어와 독일어 토크나이저 불러오기\n",
        "'''\n",
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Lx0kKCBSRHhW"
      },
      "outputs": [],
      "source": [
        "spacy_en = spacy.load('en') # 영어 토크나이저\n",
        "spacy_de = spacy.load('de') # 독일어 토크나이저"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee9P1kRbRgpl",
        "outputId": "cc8a1578-ac38-4ccb-ad7f-20f214b20d23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "인덱스 0: I\n",
            "인덱스 1: am\n",
            "인덱스 2: an\n",
            "인덱스 3: undergraduate\n",
            "인덱스 4: student\n",
            "인덱스 5: .\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "토큰화가 잘 되는지 확인\n",
        "'''\n",
        "tokenized = spacy_en.tokenizer(\"I am an undergraduate student.\")\n",
        "\n",
        "for i, token in enumerate(tokenized):\n",
        "    print(f'인덱스 {i}: {token.text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "b5bL3sa6VKsq"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "독일어, 영어 토큰화 함수 정의\n",
        "'''\n",
        "def tokenize_de(text):\n",
        "    return [token.text for token in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [token.text for token in spacy_en.tokenizer(text)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uQ9ScP6LVKUl"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Field 라이브러리를 이용해 데이터셋에 대한 구체적인 전처리 내용을 명시한다.\n",
        "- SRC(source): 독일어\n",
        "- TRG(target): 영어\n",
        "'''\n",
        "\n",
        "SRC = Field(tokenize=tokenize_de, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True)\n",
        "TRG = Field(tokenize=tokenize_en, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_jw7WClW27O",
        "outputId": "051dc5e8-8016-4043-ac4e-a6bdb293d980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.21M/1.21M [00:04<00:00, 284kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 46.3k/46.3k [00:00<00:00, 92.8kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 66.2k/66.2k [00:00<00:00, 88.3kB/s]\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "대표적인 영어-독일어 번역 데이터셋인 Multi30k를 불러온다.\n",
        "'''\n",
        "\n",
        "train_dataset, valid_dataset, test_dataset = Multi30k.splits(exts=(\".de\", \".en\"), fields=(SRC, TRG))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RudzFFQXJ4N",
        "outputId": "cd1f9c44-3ccd-460c-ec4f-fed9fc9185d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "학습 데이터셋(training dataset) 크기: 29000개\n",
            "평가 데이터셋(validation dataset) 크기: 1014개\n",
            "테스트 데이터셋(testing dataset) 크기: 1000개\n"
          ]
        }
      ],
      "source": [
        "print(f\"학습 데이터셋(training dataset) 크기: {len(train_dataset.examples)}개\")\n",
        "print(f\"평가 데이터셋(validation dataset) 크기: {len(valid_dataset.examples)}개\")\n",
        "print(f\"테스트 데이터셋(testing dataset) 크기: {len(test_dataset.examples)}개\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ6dnV2PXZgf",
        "outputId": "b8d49fa1-5cce-42e9-fe1b-874ce938a6a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ein', 'mann', ',', 'der', 'mit', 'einer', 'tasse', 'kaffee', 'an', 'einem', 'urinal', 'steht', '.']\n",
            "['a', 'man', 'standing', 'at', 'a', 'urinal', 'with', 'a', 'coffee', 'cup', '.']\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "학습 데이터 중 하나 출력\n",
        "'''\n",
        "print(vars(train_dataset.examples[30])['src'])\n",
        "print(vars(train_dataset.examples[30])['trg'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USs_wFSqYIwa",
        "outputId": "72b6a72d-939b-4080-f0f7-2bc72adb8137"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(SRC): 7855\n",
            "len(TRG): 5893\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Field 객체의 build_vocab 메서드를 이용해 영어와 독일어의 단어 사전 생성.\n",
        "최소 2번 이상 등장한 단어만을 선택한다.\n",
        "'''\n",
        "SRC.build_vocab(train_dataset, min_freq=2)\n",
        "TRG.build_vocab(train_dataset, min_freq=2)\n",
        "\n",
        "print(f\"len(SRC): {len(SRC.vocab)}\")\n",
        "print(f\"len(TRG): {len(TRG.vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dMpevooYtk5",
        "outputId": "77e033d8-d8d7-4be7-c38a-327378336ae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4112\n",
            "1752\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "OOV는 0, 패딩은 1, <sos>, <eos>는 각각 2, 3이며 해당하는 단어에 대해 인덱스를 출력한다.\n",
        "'''\n",
        "print(TRG.vocab.stoi[\"OutOfVocabulary\"]) # 없는 단어: 0\n",
        "print(TRG.vocab.stoi[TRG.pad_token]) # 패딩(padding): 1\n",
        "print(TRG.vocab.stoi[\"<sos>\"]) # <sos>: 2\n",
        "print(TRG.vocab.stoi[\"<eos>\"]) # <eos>: 3\n",
        "print(TRG.vocab.stoi[\"hello\"])\n",
        "print(TRG.vocab.stoi[\"world\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YWvLsrKSYwFu"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "디바이스를 정의한다.\n",
        "'''\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WDA2N15UZTLa"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "한 문장에 포함된 단어가 연속적으로 RNN에 입력되어야 하므로,\n",
        "하나의 배치에 포함된 문장들이 가지는 단어의 개수가 유사하도록 만든다.\n",
        "\n",
        "이를 위해 BucketIterator를 사용한다.\n",
        "매 epoch마다 문장을 새로 섞어 배치를 구성하고, 필요한 padding의 크기를 최소화할 수 있다.\n",
        "배치 크기(batch size): 128\n",
        "'''\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_dataset, valid_dataset, test_dataset),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8mhznL3aC4V",
        "outputId": "2d9b2c1b-35d1-4e3e-d20e-07ad26f713a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0번째 배치 크기: torch.Size([27, 128])\n",
            "2\n",
            "5\n",
            "70\n",
            "26\n",
            "7\n",
            "6\n",
            "3008\n",
            "128\n",
            "7092\n",
            "17\n",
            "1499\n",
            "4\n",
            "3\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "for i, batch in enumerate(train_iterator):\n",
        "    src = batch.src\n",
        "    trg = batch.trg\n",
        "\n",
        "    print(f\"{i}번째 배치 크기: {src.shape}\")\n",
        "\n",
        "    # 현재 배치에 있는 하나의 문장에 포함된 정보 출력\n",
        "    for i in range(src.shape[0]):\n",
        "        print(f\"{src[i][0].item()}\")\n",
        "\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq-p1pwteVLK"
      },
      "source": [
        "# Building the Seq2Seq Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFFbH6GnfqP1"
      },
      "source": [
        "## Encoder\n",
        "input sequence를 context vector로 인코딩한다.\n",
        "\n",
        "hyperparemeter\n",
        "- input_dim: 하나의 단어에 대한 원 핫 인코딩 차원\n",
        "- embed_dim: 임베딩 차원\n",
        "- enc_hidden_dim: encoder hidden state dimension\n",
        "- dec_hidden_dim: decoder hidden state dimension\n",
        "- dropout_ratio: 드랍아웃 비율"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1ZJsFFf5alAv"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, embed_dim, enc_hidden_dim, dec_hidden_dim, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        # embedding은 원 핫 인코딩을 특정 차원의 임베딩으로 매핑하는 레이어\n",
        "        self.embedding = nn.Embedding(input_dim, embed_dim)\n",
        "\n",
        "        # 양방향 GRU 레이어\n",
        "        self.rnn = nn.GRU(embed_dim, enc_hidden_dim, bidirectional=True)\n",
        "\n",
        "        # FC 레이어\n",
        "        self.fc = nn.Linear(enc_hidden_dim * 2, dec_hidden_dim)\n",
        "\n",
        "        # 드랍아웃\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "    \n",
        "    # 인코더는 소스 문장을 입력으로 받아 문맥 벡터(context vector)를 반환   \n",
        "    def forward(self, src):\n",
        "        # src: [src len(단어 개수), batch size(배치 크기)]: 각 단어의 인덱스 정보\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        # embedded = [src len(단어 개수), batch size(배치 크기), emb dim(임베딩 차원)]\n",
        "\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        # outputs: [단어 개수, 배치 크기, 인코더 히든 차원 * drection 수]: 전체 단어의 출력 정보\n",
        "        # hidden: [레이어 개수 * direction 수, 배치 크기, 인코더 히든 차원]: 현재까지의 모든 단어의 정보\n",
        "\n",
        "        # hidden은 [forward_1, backward_1, forward_2, backward_2, ...] 형태로 구성\n",
        "        # 따라서 hidden[-2,:,:]은 forwards의 마지막 값\n",
        "        # 따라서 hidden[-1,:,:]은 backwards의 마지막 값\n",
        "        # 디코더의 첫번째 hidden (context) vector는 인코더의 마지막 hidden을 이용\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n",
        "\n",
        "        # outputs은 Attention 목적으로 hidden은 context vector 목적으로 사용\n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObH93RjS2c24"
      },
      "source": [
        "## Attention\n",
        "하나의 Attention은 인코더 전체 토큰에 대한 출력을 입력으로 받는 FC의 파라미터를 공유하여 사용한다.\n",
        "\n",
        "(전체 인코더 출력(context vector) + 현재 디코더의 히든(input of decoder)) -> 디코더의 히든 -> 실제 Attention 값\n",
        "\n",
        "hyperparameter\n",
        "- enc_hidden_dim: encoder hidden state dimension\n",
        "- dec_hidden_dim: decoder hidden state dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OBWTHWaXzq7y"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hidden_dim, dec_hidden_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attn = nn.Linear((enc_hidden_dim * 2) + dec_hidden_dim, dec_hidden_dim)\n",
        "        self.v = nn.Linear(dec_hidden_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, enc_outputs):\n",
        "        # hidden: [배치 크기, 히든 차원]: 현재까지의 모든 단어의 정보\n",
        "        # enc_outputs: [단어 개수, 배치 크기, 인코더 히든 차원 * 방향의 수]: 전체 단어의 출력 정보\n",
        "        batch_size = enc_outputs.shape[1]\n",
        "        src_len = enc_outputs.shape[0]\n",
        "\n",
        "        # 현재 디코더의 히든 상태(hidden state)를 src_len만큼 반복\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        enc_outputs = enc_outputs.permute(1, 0, 2)\n",
        "        # hidden: [배치 크기, 단어 개수, 디코더 히든 차원]: 현재까지의 모든 단어의 정보\n",
        "        # enc_outputs: [배치 크기, 단어 개수, 인코더 히든 차원 * 방향의 수]: 전체 단어의 출력 정보\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, enc_outputs), dim=2)))\n",
        "        # energy: [배치 크기, 단어 개수, 디코더 히든 차원]\n",
        "\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        # attention: [배치 크기, 단어 개수]: 실제 각 단어에 대한 어텐선(attention) 값들\n",
        "\n",
        "        return F.softmax(attention, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3q3yk7s-bT7"
      },
      "source": [
        "## Decoder\n",
        "주어진 context vector를 타겟 문장으로 decoding한다.\n",
        "\n",
        "decoding하는 과정에서 매번 인코더의 모든 출력에 대하여 attention을 수행한다.\n",
        "\n",
        "hyperparameter\n",
        "- output_dim: 하나의 단어에 대한 원 핫 인코딩 차원\n",
        "- embed_dim: embedding dimension\n",
        "- enc_hidden_dim: encoder hidden state dimension\n",
        "- dec_hidden_dim: decoder hidden state dimension\n",
        "- dropout_ratio: 드랍아웃 비율"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PF0RBUqY4e3b"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, embed_dim, enc_hidden_dim, dec_hidden_dim, dropout_ratio, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "\n",
        "        # 임베딩(embedding)은 원 핫 인코딩 말고 특정 차원의 임베딩으로 매핑하는 레이어\n",
        "        self.embedding = nn.Embedding(output_dim, embed_dim)\n",
        "\n",
        "        # GRU 레이어\n",
        "        self.rnn = nn.GRU((enc_hidden_dim * 2) + embed_dim, dec_hidden_dim)\n",
        "\n",
        "        # FC 레이어\n",
        "        self.fc_out = nn.Linear((enc_hidden_dim * 2) + dec_hidden_dim + embed_dim, output_dim)\n",
        "\n",
        "        # 드롭아웃(dropout)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    # 디코더는 현재까지 출력된 문장에 대한 정보를 입력으로 받아 타겟 문장을 반환\n",
        "    def forward(self, input, hidden, enc_outputs):\n",
        "        # input: [배치 크기]: 단어의 개수는 항상 1개이도록 구현\n",
        "        # hidden: [배치 크기, 히든 차원]\n",
        "        # enc_outputs: [단어 개수, 배치 크기, 인코더 히든 차원 * 방향의 수]: 전체 단어의 출력 정보\n",
        "        input = input.unsqueeze(0)\n",
        "        # input: [단어 개수 = 1, 배치 크기]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # embedded: [단어 개수 = 1, 배치 크기, 임베딩 차원]\n",
        "\n",
        "        attention = self.attention(hidden, enc_outputs)\n",
        "        # attention: [배치 크기, 단어 개수]: 실제 각 단어에 대한 어텐선(attention) 값들\n",
        "        attention = attention.unsqueeze(1)\n",
        "        # attention: [배치 크기, 1, 단어 개수]: 실제 각 단어에 대한 어텐선(attention) 값들\n",
        "\n",
        "        enc_outputs = enc_outputs.permute(1, 0, 2)\n",
        "        # enc_outputs: [배치 크기, 단어 개수, 인코더 히든 차원 * 방향의 수]: 전체 단어의 출력 정보\n",
        "\n",
        "        weighted = torch.bmm(attention, enc_outputs) # 행렬 곱 함수\n",
        "        # weighted: [배치 크기, 1, 인코더 히든 차원 * 방향의 수]\n",
        "\n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        # weighted: [1, 배치 크기, 인코더 히든 차원 * 방향의 수]\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
        "        # rnn_input: [1, 배치 크기, 인코더 히든 차원 * 방향의 수 + embed_dim]: 어텐션이 적용된 현재 단어 입력 정보\n",
        "\n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        # output: [단어 개수, 배치 크기, 디코더 히든 차원 * 방향의 수]\n",
        "        # hidden: [레이어 개수 * 방향의 수, 배치 크기, 디코더 히든 차원]: 현재까지의 모든 단어의 정보\n",
        "\n",
        "        # 현재 예제에서는 단어 개수, 레이어 개수, 방향의 수 모두 1의 값을 가짐\n",
        "        # 따라서 output: [1, 배치 크기, 디코더 히든 차원], hidden: [1, 배치 크기, 디코더 히든 차원]\n",
        "        # 다시 말해 output과 hidden의 값 또한 동일\n",
        "        assert (output == hidden).all()\n",
        "\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "\n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
        "        # prediction = [배치 크기, 출력 차원]\n",
        "\n",
        "        # (현재 출력 단어, 현재까지의 모든 단어의 정보)\n",
        "        return prediction, hidden.squeeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fPfQaVvxM0i"
      },
      "source": [
        "## Seq2Seq\n",
        "위에서 정의한 인코더와 디코더를 가지고 있는 하나의 아키텍처이다.\n",
        "- Encoder: 주어진 input sequence를 context vector로 인코딩한다.\n",
        "- 인코더는 최종 hidden state와 모든 hidden state를 반환한다. 이때, 최종 hidden state는 디코더의 첫번째 hidden state로 사용된다.\n",
        "- Decoder: 주어진 context vector를 target sequence로 디코딩한다.\n",
        "- 디코더는 한 단어씩 넣어서 한 번씩 결과를 구한다.\n",
        "- 디코더는 context vector 예측과 인코더의 모든 출력을 참고하여 attention을 진행한다.\n",
        "\n",
        "Teacher forcing: 디코더의 prediction을 다음 입력으로 사용하지 않고, ground-truth를 다음 입력으로 사용하는 기법.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6w2_nSPhDqJ7"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    # 학습할 때는 완전한 형태의 소스 문장, 타겟 문장, teacher_forcing_ratio를 넣기\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        # src: [단어 개수, 배치 크기]\n",
        "        # trg: [단어 개수, 배치 크기]\n",
        "\n",
        "        # 먼저 인코더를 거쳐 전체 출력과 문맥 벡터(context vector)를 추출\n",
        "        enc_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        trg_len = trg.shape[0] # 단어 개수\n",
        "        batch_size = trg.shape[1] # 배치 크기\n",
        "        trg_vocab_size = self.decoder.output_dim # 출력 차원\n",
        "\n",
        "        # 디코더(decoder)의 최종 결과를 담을 텐서 객체 만들기\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        # 첫 번째 입력은 항상 <sos> 토큰\n",
        "        input = trg[0, :]\n",
        "\n",
        "        # 타겟 단어의 개수만큼 반복하여 디코더에 포워딩(forwarding)\n",
        "        for t in range(1, trg_len):\n",
        "            # insert input sequence, 가장 최신의 hidden state 와 모든 인코더 hidden state를 디코더에 전달한다.\n",
        "            # output: 예측한 결과 텐서(predictions)\n",
        "            # hidden: 디코더 hidden state\n",
        "            output, hidden = self.decoder(input, hidden, enc_outputs)\n",
        "\n",
        "            # FC를 거쳐서 나온 현재의 출력 단어 정보\n",
        "            # 매 반복마다 outputs에 예측된 결과를 저장한다.\n",
        "            outputs[t] = output\n",
        "\n",
        "            top1 = output.argmax(1) # 가장 확률이 높은 단어의 인덱스 추출\n",
        "\n",
        "            # teacher_forcing_ratio: 학습할 때 실제 목표 출력(ground-truth)을 사용하는 비율\n",
        "            # 기본적으로 모든 예측의 50%를 teacher force한다.\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "            input = trg[t] if teacher_force else top1 # 현재의 출력 결과를 다음 입력에서 넣기\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KoFRRQt5HAI"
      },
      "source": [
        "# 학습(Training)\n",
        "하이퍼 파라미터 설정 및 모델 초기화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VNTu_1lx0MsS"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENCODER_EMBED_DIM = 256\n",
        "DECODER_EMBED_DIM = 256\n",
        "ENCODER_HIDDEN_DIM = 512\n",
        "DECODER_HIDDEN_DIM = 512\n",
        "ENC_DROPOUT_RATIO = 0.5\n",
        "DEC_DROPOUT_RATIO = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vOAfk9s_5Mbs"
      },
      "outputs": [],
      "source": [
        "# 어텐션(attention) 객체 선언\n",
        "attn = Attention(ENCODER_HIDDEN_DIM, DECODER_HIDDEN_DIM)\n",
        "\n",
        "# 인코더(encoder)와 디코더(decoder) 객체 선언\n",
        "enc = Encoder(INPUT_DIM, ENCODER_EMBED_DIM, ENCODER_HIDDEN_DIM, DECODER_HIDDEN_DIM, ENC_DROPOUT_RATIO)\n",
        "dec = Decoder(OUTPUT_DIM, DECODER_EMBED_DIM, ENCODER_HIDDEN_DIM, DECODER_HIDDEN_DIM, DEC_DROPOUT_RATIO, attn)\n",
        "\n",
        "# Seq2Seq 객체 선언\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UslqnRz5bJS"
      },
      "source": [
        "모델 가중치 파라미터 초기화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc_n3FTw5VLF",
        "outputId": "d8bac8d7-fd24-4cd5-ab52-8f3d322705b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(7855, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(5893, 256)\n",
              "    (rnn): GRU(1280, 512)\n",
              "    (fc_out): Linear(in_features=1792, out_features=5893, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1UMhBTj5uok"
      },
      "source": [
        "학습 및 평가 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oEWOag_h5e3H"
      },
      "outputs": [],
      "source": [
        "# Adam optimizer로 학습 최적화\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# 뒷 부분의 패딩(padding)에 대해서는 값 무시\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "A9KCXTk75xRl"
      },
      "outputs": [],
      "source": [
        "# 모델 학습(train) 함수\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train() # 학습 모드\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    # 전체 학습 데이터를 확인하며\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "        # output: [출력 단어 개수, 배치 크기, 출력 차원]\n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        # 출력 단어의 인덱스 0은 사용하지 않음\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        # output = [(출력 단어의 개수 - 1) * batch size, output dim]\n",
        "        trg = trg[1:].view(-1)\n",
        "        # trg = [(타겟 단어의 개수 - 1) * batch size]\n",
        "        \n",
        "        # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward() # 기울기(gradient) 계산\n",
        "        \n",
        "        # 기울기(gradient) clipping 진행\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        # 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "        \n",
        "        # 전체 손실 값 계산\n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vr8olz3w51WU"
      },
      "outputs": [],
      "source": [
        "# 모델 평가(evaluate) 함수\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval() # 평가 모드\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        # 전체 평가 데이터를 확인하며\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            # 평가할 때 teacher forcing는 사용하지 않음\n",
        "            output = model(src, trg, 0)\n",
        "            # output: [출력 단어 개수, 배치 크기, 출력 차원]\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            # 출력 단어의 인덱스 0은 사용하지 않음\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            # output = [(출력 단어의 개수 - 1) * batch size, output dim]\n",
        "            trg = trg[1:].view(-1)\n",
        "            # trg = [(타겟 단어의 개수 - 1) * batch size]\n",
        "\n",
        "            # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            # 전체 손실 값 계산\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xv6mw7R54EC"
      },
      "source": [
        "학습(training) 및 검증(validation) 진행\n",
        "- Epoch는 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "eUDVeXFS53Zi"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBcYQdUw6Apw",
        "outputId": "7ebffb43-1085-4e5c-d934-a76406cd75df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 2m 45s\n",
            "\tTrain Loss: 5.039 | Train PPL: 154.383\n",
            "\tValidation Loss: 5.088 | Validation PPL: 162.090\n",
            "Epoch: 02 | Time: 2m 44s\n",
            "\tTrain Loss: 4.180 | Train PPL: 65.356\n",
            "\tValidation Loss: 4.486 | Validation PPL: 88.786\n",
            "Epoch: 03 | Time: 2m 44s\n",
            "\tTrain Loss: 3.522 | Train PPL: 33.857\n",
            "\tValidation Loss: 3.710 | Validation PPL: 40.862\n",
            "Epoch: 04 | Time: 2m 44s\n",
            "\tTrain Loss: 2.961 | Train PPL: 19.316\n",
            "\tValidation Loss: 3.415 | Validation PPL: 30.432\n",
            "Epoch: 05 | Time: 2m 46s\n",
            "\tTrain Loss: 2.567 | Train PPL: 13.033\n",
            "\tValidation Loss: 3.293 | Validation PPL: 26.932\n",
            "Epoch: 06 | Time: 2m 43s\n",
            "\tTrain Loss: 2.257 | Train PPL: 9.558\n",
            "\tValidation Loss: 3.163 | Validation PPL: 23.650\n",
            "Epoch: 07 | Time: 2m 42s\n",
            "\tTrain Loss: 1.989 | Train PPL: 7.310\n",
            "\tValidation Loss: 3.182 | Validation PPL: 24.091\n",
            "Epoch: 08 | Time: 2m 43s\n",
            "\tTrain Loss: 1.808 | Train PPL: 6.099\n",
            "\tValidation Loss: 3.221 | Validation PPL: 25.056\n",
            "Epoch: 09 | Time: 2m 43s\n",
            "\tTrain Loss: 1.638 | Train PPL: 5.145\n",
            "\tValidation Loss: 3.274 | Validation PPL: 26.425\n",
            "Epoch: 10 | Time: 2m 46s\n",
            "\tTrain Loss: 1.506 | Train PPL: 4.507\n",
            "\tValidation Loss: 3.287 | Validation PPL: 26.760\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time() # 시작 시간 기록\n",
        "\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time() # 종료 시간 기록\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'seq2seq_with_attention.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')\n",
        "    print(f'\\tValidation Loss: {valid_loss:.3f} | Validation PPL: {math.exp(valid_loss):.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wwC0jBxB6EU4",
        "outputId": "a8836503-74fe-4318-d0fa-53229bbac1bc"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_100f51be-7d05-4cfb-8553-f5fcbb4440a8\", \"seq2seq_with_attention.pt\", 82080196)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 학습된 모델 저장\n",
        "from google.colab import files\n",
        "\n",
        "files.download('seq2seq_with_attention.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2JxZ6P07UAt"
      },
      "source": [
        "모델 최종 테스트(testing) 결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvbNf5dd6HO8",
        "outputId": "ca750b96-6c2a-41d6-ea2f-15de2f087e49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 3.168 | Test PPL: 23.770\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('seq2seq_with_attention.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW6tA1_e8esW"
      },
      "source": [
        "모델 사용해보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "cZA9Mdcy8dmn"
      },
      "outputs": [],
      "source": [
        "# 번역(translation) 함수\n",
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len=50):\n",
        "    model.eval() # 평가 모드\n",
        "\n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('de')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # 처음에 <sos> 토큰, 마지막에 <eos> 토큰 붙이기\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "    print(f\"전체 소스 토큰: {tokens}\")\n",
        "\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    print(f\"소스 문장 인덱스: {src_indexes}\")\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    # 인코더(endocer)에 소스 문장을 넣어 문맥 벡터(context vector) 계산\n",
        "    with torch.no_grad():\n",
        "        enc_outputs, hidden = model.encoder(src_tensor)\n",
        "\n",
        "    # 처음에는 <sos> 토큰 하나만 가지고 있도록 하기\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "        # 이전에 출력한 단어가 현재 단어로 입력될 수 있도록\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden = model.decoder(trg_tensor, hidden, enc_outputs)\n",
        "\n",
        "        pred_token = output.argmax(1).item()\n",
        "        trg_indexes.append(pred_token) # 출력 문장에 더하기\n",
        "\n",
        "        # <eos>를 만나는 순간 끝\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "\n",
        "    # 각 출력 단어 인덱스를 실제 단어로 변환\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "\n",
        "    # 첫 번째 <sos>는 제외하고 출력 문장 반환\n",
        "    return trg_tokens[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u83M9w8q8u3t",
        "outputId": "3de681fc-abee-4522-e224-987a79960854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "소스 문장: ['ein', 'mädchen', 'in', 'einem', 'jeanskleid', 'läuft', 'über', 'einen', 'erhöhten', 'schwebebalken', '.']\n",
            "타겟 문장: ['a', 'girl', 'in', 'a', 'jean', 'dress', 'is', 'walking', 'along', 'a', 'raised', 'balance', 'beam', '.']\n",
            "전체 소스 토큰: ['<sos>', 'ein', 'mädchen', 'in', 'einem', 'jeanskleid', 'läuft', 'über', 'einen', 'erhöhten', 'schwebebalken', '.', '<eos>']\n",
            "소스 문장 인덱스: [2, 5, 25, 7, 6, 0, 83, 42, 19, 3199, 2669, 4, 3]\n",
            "모델 출력 결과: a girl in a <unk> outfit runs across a <unk> course . <eos>\n"
          ]
        }
      ],
      "source": [
        "example_idx = 15\n",
        "\n",
        "src = vars(test_dataset.examples[example_idx])['src']\n",
        "trg = vars(test_dataset.examples[example_idx])['trg']\n",
        "\n",
        "print(f'소스 문장: {src}')\n",
        "print(f'타겟 문장: {trg}')\n",
        "print(\"모델 출력 결과:\", \" \".join(translate_sentence(src, SRC, TRG, model, device)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Cusd5638w0a",
        "outputId": "d5968172-4748-402d-cc5b-5e37c90f507f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "소스 문장: ['Guten', 'Tag', '.']\n",
            "전체 소스 토큰: ['<sos>', 'guten', 'tag', '.', '<eos>']\n",
            "소스 문장 인덱스: [2, 3799, 200, 4, 3]\n",
            "모델 출력 결과: a day at night . <eos>\n"
          ]
        }
      ],
      "source": [
        "src = tokenize_de(\"Guten Tag.\")\n",
        "\n",
        "print(f'소스 문장: {src}')\n",
        "print(\"모델 출력 결과:\", \" \".join(translate_sentence(src, SRC, TRG, model, device)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xVScZCC8yGU",
        "outputId": "08f96de7-a191-4c8c-cebc-a691bb40d655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "소스 문장: ['Guten', 'Morgen', '.']\n",
            "전체 소스 토큰: ['<sos>', 'guten', 'morgen', '.', '<eos>']\n",
            "소스 문장 인덱스: [2, 3799, 3352, 4, 3]\n",
            "모델 출력 결과: protesters are going to start . <eos>\n"
          ]
        }
      ],
      "source": [
        "src = tokenize_de(\"Guten Morgen.\")\n",
        "\n",
        "print(f'소스 문장: {src}')\n",
        "print(\"모델 출력 결과:\", \" \".join(translate_sentence(src, SRC, TRG, model, device)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Gxab_vVCYWu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPFKx1P+IL1iMRWQyitY+ar",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Seq2Seq with Attention Machine Translation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
